{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1933c33b",
   "metadata": {},
   "source": [
    "# Visualizing a Wire Plane Image Tutorial\n",
    "\n",
    "This Tutorial Notebook shows how to view the input wire plane images. We also explain the contents of the image a little and define some jargon used by the group and by the collaboration.\n",
    "\n",
    "You can get an example file from:\n",
    "\n",
    "https://drive.google.com/drive/folders/1LOOLHZJYLmOZAiGT4IAgmZwgUGTRjBdD?usp=sharing\n",
    "\n",
    "By default, the notebook will reference the following file:\n",
    "\n",
    "`dlmerged_larflowtruth_mcc9_v13_bnbnue_corsika_run00001_subrun00001.root`\n",
    "\n",
    "This is simulated data. It contains simulated inputs that go into the reconstruction workflow. \n",
    "It also contains, \"truth\" information saved from the simulation that helps us generate labels and study the performance of the reconstruction and quantify the accuracy of physics analyses based.\n",
    "\n",
    "In this notebook you will see:\n",
    "* The class we use to interface with this type of file\n",
    "* Some utility functions we have built, based on the plotly graphics library, to do visualization\n",
    "\n",
    "------\n",
    "\n",
    "Some classes and functions used in this tutorial:\n",
    "\n",
    "* [larcv::IOManager](https://github.com/LArbys/LArCV/blob/develop/larcv/core/DataFormat/IOManager.h)\n",
    "* [larcv::Image2D](https://github.com/LArbys/LArCV/blob/develop/larcv/core/DataFormat/Image2D.h)\n",
    "* [plotly heatmap](https://plotly.com/python/heatmaps/)\n",
    "* [lardly image2d plot makeing function](https://github.com/LArbys/lardly/blob/48efe52d8dd51bac2c0644be9ab6749f4e241b45/lardly/data/larcv_image2d.py#L8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc4c012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import basic python utilities along  with plotly\n",
    "# If you get an error saying that the plotly library is not found, you can install it via:\n",
    "#  pip3 install plotly\n",
    "\n",
    "import os,sys\n",
    "import plotly as pl # import the plotly library\n",
    "import plotly.graph_objects as go # import interfaces that helps us create different types of plots\n",
    "\n",
    "# magic jupyter notebook command to reload modules\n",
    "# so we can change them and get an effect without restarting the notebook\n",
    "%load_ext autoreload  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35553eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ROOT library\n",
    "# if you see errors, you might check that\n",
    "#  * did you configure the environment in the shell before calling jupyter-notebook?\n",
    "#    This usually means calling, source setenv_py3.sh; source configure.sh in the top-level of the repo\n",
    "#  * the build didn't complete properly. After setting the evironment above, \n",
    "#    try calling `source buildall_py3.sh` again\n",
    "\n",
    "import ROOT as rt # You should see a message like, \"Welcome to JupyROOT [version]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de75564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the libraries our group has written\n",
    "from larlite import larlite # stores list of tabular data related an event\n",
    "from larcv import larcv # stores data related to the wire plane signals represented as an image\n",
    "from ublarcvapp import ublarcvapp # utility functions that interfaces between the image and tabular data\n",
    "import lardly # utility functions that create default plots (3d scatter, 2d heat maps) for our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa35306",
   "metadata": {},
   "source": [
    "Below we specify the location of the file we want to use.\n",
    "\n",
    "For a list of example files, refer to this [list](https://github.com/NuTufts/icdl/wiki/Locations-of-Tutorial-Files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251c73da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify location of the file we want to open\n",
    "\n",
    "# For list of tutorial files check out []\n",
    "inputfile = \"dlmerged_larflowtruth_mcc9_v13_bnbnue_corsika_run00001_subrun00001.root\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf9e222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the ROOT file and use a command to list the contents\n",
    "#\n",
    "# you'll see a lot of TTree objects. \n",
    "# These are essentially tables of data with a specific schema, \n",
    "#   with each row of data consisting of one \"event\".\n",
    "\n",
    "rfile = rt.TFile(inputfile,\"open\")\n",
    "rfile.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a2e98e",
   "metadata": {},
   "source": [
    "We do not access the data (i.e. the TTrees) directly). \n",
    "\n",
    "The ROOT trees store data in the form of serialized instances of custom C++ classes. \n",
    "\n",
    "In otherwords, for each event, copies of C++ classes are turned into a binary string, storing the values of its data members. \n",
    "\n",
    "Unpacking this involves de-serializing the class data and giving back a set of C++ class instances for each event. \n",
    "\n",
    "Not only that, but we have to coordinate the access of the trees so that the data from each is for the same event.\n",
    "\n",
    "This is obviously complicated. We have special classes of our own that interfaces with ROOT's IO functions to help us do this. The data input/output inferface class for LArCV-type trees is `larcv::IOManager`.\n",
    "\n",
    "If you want to look at the header, follow this [link](https://github.com/LArbys/LArCV/blob/develop/larcv/core/DataFormat/IOManager.h).\n",
    "\n",
    "For this notebook, we are after `image2d` objects, which store the wireplane data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0550343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the larcv IOManager class to load the trees for us.\n",
    "\n",
    "# Initialize an IOManager instance that will read out input file\n",
    "\n",
    "# There is this annoying feature left over from a code choice early on in development of LArCV.\n",
    "# We initially stored images in the computer vision tradition, with the origin in the upper left.\n",
    "# We later realized this was confusing and started storing images in a more physicist friendly \n",
    "#  convention which is the origin is in the lower right hange corner.\n",
    "# But we still work with files made in the old way.\n",
    "# So we need to specify if the images are in the old (tick backward) or new format (tick forward)\n",
    "\n",
    "tick_order = larcv.IOManager.kTickBackward\n",
    "#tick_order = larcv.IOManager.kTickForward\n",
    "\n",
    "io = larcv.IOManager( larcv.IOManager.kREAD, \"larcv\", tick_order )\n",
    "io.add_in_file( inputfile )\n",
    "\n",
    "# If the format is in the old way, flip it\n",
    "if tick_order==larcv.IOManager.kTickBackward:\n",
    "    io.reverse_all_products()\n",
    "io.initialize()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d3a9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we load an entry in the file.\n",
    "# Each entry contains one \"Event\".\n",
    "# An event is defined as the time, we gave the order to save a picture from the detector.\n",
    "# We usually do this in coordination when the neutrino beam is fired.\n",
    "\n",
    "ENTRY_NUM = 2\n",
    "io.read_entry(ENTRY_NUM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e58883",
   "metadata": {},
   "source": [
    "As mentioned previously, the format of data isn't simple (copies of C++ classes), and each file holds many different types of data in different trees (see the list above).\n",
    "\n",
    "So we have to tell the interface what type of data to load from the event.\n",
    "\n",
    "It usually returns a contain (think list or c++ vector), with all the copies of that type of data for an event.\n",
    "\n",
    "For the wire plane images, each event contains three images. Each image corresponds to the wire planes of the MicroBooNE liquid argon TPC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05cb4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the images from the tree storing the wireplane images\n",
    "\n",
    "# we retrieve a container with all the wireplane images for the event\n",
    "event_image_data = io.get_data( larcv.kProductImage2D, \"wiremc\" )\n",
    "#event_image_data = io.get_data( larcv.kProductImage2D, \"ancestor\" )\n",
    "\n",
    "# we get a std::vector<larcv::Image2D> object that has the data\n",
    "adc_v = event_image_data.as_vector()\n",
    "\n",
    "# print the number of images in the vector\n",
    "# usually, if this is a MicroBooNE file you should get 3 images: one for each wireplane U, V, and Y.\n",
    "print(\"number of images in this event: \",adc_v.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbae7e6",
   "metadata": {},
   "source": [
    "We loop through each image in the event and make a picture.\n",
    "\n",
    "The wire plane images are stored in the order:\n",
    " * the U-Induction plane\n",
    " * the V-Induction plane\n",
    " * the Y-Induction plane\n",
    " \n",
    "The image data is stored in a `larcv::Image2D` object. You can refer to its header file [here](https://github.com/LArbys/LArCV/blob/develop/larcv/core/DataFormat/Image2D.h) to see what data it holds and what kind of functions it has.\n",
    " \n",
    "If you used the file `dlmerged_larflowtruth_mcc9_v13_bnbnue_corsika_run00001_subrun00001.root` and accessed Entry 0, you will see a electron neutrino interaction. You can find the location of the interaction in each plane at:\n",
    " * U plane: (x,y)=(column,row)=(wire,tick)=(1648,5496)\n",
    " * V plane: (x,y)=(2230,5478)\n",
    " * Y plane: (x,y)=(3216,5508)\n",
    " \n",
    "What we looking at exactly? This is the output of MicroBooNE's liquid argon time projection chamber. Specifically it is the output of its charge-sensitive wire planes.\n",
    "\n",
    "What it is ultimately telling us is the locations in the detector where charged particles traveled and left behind energy in the detector. The portion of the energy that we can see through these images is the fraction used to create \"ionization electrons\".  When a charged particle passes by an argon atom, the atom feels the particles presence through it's electric charge. This charge can push on the electrons of the argon atom and ultimately liberate electrons from the argon atom in a process called \"ionization\". \n",
    "\n",
    "What the color scale shows us in the images is how many ionizations electrons were created at a given location in the detector.\n",
    "\n",
    "OK, that's not quite the full story. What we actually see is the PROJECTED location of the ionization, not the true 3D position in the detector. We ultimately have to do some work to put the three images together (along with timing information from other pieces of data from the detector) to get the 3D location. But-- we can still look at the pictures and pick out interesting pieces of information, such as identify neutrino interactions and recognize individual particles.\n",
    " \n",
    "You can see three particles being created in this interaction. The point where the three particles start is the location where the neutrino interacted with an argon nucleus. We refer to this location as the \"vertex\". From the vertex emerges different particles. If the particles have charge, then we can see them. Often, when we look at data, we need to run algorithms to decide what type of charged particle was created. When we don't know the name of a particle, we often refer to it (or more precisely the pattern of energy left behind) as a \"prong\".\n",
    " \n",
    "The first is an electron which starts off as a line then quickly begins to exhibit branch-like patterns. This is because electrons create what are called \"electromagnetic showers\" or \"showers\".\n",
    " \n",
    " There are also two protons which are ejected from the nucleus that was hit by the neutrino. The first is fairly energetic. It goes off and then makes a sharp turn as the proton interacts with a second argon nucleus. The second proton is fairly low energy. Can you spot the short line of heavy energy deposition near the interaction vertex?\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a602247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we loop through each image in the event and make a picture\n",
    "# the wire plane images are stored in the order:\n",
    "#  the U-Induction plane\n",
    "#  the V-Induction plane\n",
    "#  the Y-Induction plane\n",
    "\n",
    "fig_v = []\n",
    "for iplane in range(adc_v.size()):\n",
    "    # get a copy of the image from the container\n",
    "    plane_image = adc_v.at(iplane) # returns an object of type larcv::Image2D\n",
    "    \n",
    "    # use a lardly utility function to generate a 2D image from the larcv::Image2D object\n",
    "    plane_plot = lardly.data.visualize_larcv_image2d( plane_image, reverse_ticks=False, maxz=100.0 )\n",
    "\n",
    "    # ise plotly to show the image\n",
    "    fig = go.Figure( data=[plane_plot] )\n",
    "    fig.show()\n",
    "    \n",
    "    # put the fig in a list to keep the variable in scope\n",
    "    fig_v.append(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445a6eea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
